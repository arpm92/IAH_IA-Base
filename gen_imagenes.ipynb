{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arpm92/IAH_IA-Base/blob/main/gen_imagenes.ipynb)\n"
      ],
      "metadata": {
        "id": "niibNPnHG0Sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stable Diffusion** \n",
        "*...using `Жdiffusers`*\n",
        "\n",
        "Stable Diffusion es un modelo de difusi贸n latente texto-imagen creado por los investigadores e ingenieros de [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/) y [LAION](https://laion.ai/). Est谩 entrenado con im谩genes de 512x512 de un subconjunto de la base de datos [LAION-5B](https://laion.ai/blog/laion-5b/). Este modelo utiliza un codificador de texto congelado CLIP ViT-L/14 para condicionar el modelo a las indicaciones de texto. Con sus 860M de UNet y 123M de codificador de texto, el modelo es relativamente ligero y puede ejecutarse en muchas GPU de consumo.\n",
        "Consulta la [ficha del modelo](https://huggingface.co/CompVis/stable-diffusion) para obtener m谩s informaci贸n.\n",
        "\n",
        "Este cuaderno de Colab muestra c贸mo usar Stable Diffusion con la  Hugging Face [Ж Diffusers library](https://github.com/huggingface/diffusers).\n",
        "\n",
        "隆Vamos a empezar!"
      ],
      "metadata": {
        "id": "KaCNC7k1HB0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. C贸mo utilizar `StableDiffusionPipeline\n",
        "\n",
        "Antes de sumergirnos en los aspectos te贸ricos de c贸mo funciona Stable Diffusion,\n",
        "vamos a probarlo un poco .\n",
        "\n",
        "En esta secci贸n, mostramos c贸mo puede ejecutar la inferencia de texto a imagen 隆en s贸lo unas pocas l铆neas de c贸digo!"
      ],
      "metadata": {
        "id": "OI4D7ZPNHOOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuraci贸n\n",
        "\n",
        "En primer lugar, por favor, aseg煤rese de que est谩 utilizando un runtime GPU para ejecutar este cuaderno, por lo que la inferencia es mucho m谩s r谩pida. Si el siguiente comando falla, utilice el men煤 `Runtime` de arriba y seleccione `Change runtime type`."
      ],
      "metadata": {
        "id": "ncUze4r2HSnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "ZU-tm8ZtHUdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages: diffusers, transformers, and accelerate\n",
        "!pip install diffusers transformers accelerate torch --quiet\n",
        "\n",
        "# Install a specific version of the xformers package for performance improvements\n",
        "!pip install xformers --quiet"
      ],
      "metadata": {
        "id": "rC4jbHzJLmuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "FGGx-gNDLsTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Stable Diffusion model from the Hugging Face Model Hub\n",
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "\n",
        "# Move the pipeline to GPU for faster generation\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "fuAtQBZTLusC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a grid of images\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows * cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols * w, rows * h))\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "\n",
        "    return grid"
      ],
      "metadata": {
        "id": "8JdEwVvcLw1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of inference steps\n",
        "num_inference_steps = 50\n",
        "# Set the seed for reproducibility\n",
        "generator = torch.manual_seed(42)  # Change seed for different results"
      ],
      "metadata": {
        "id": "qcp9vKQ1Njhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define grid size\n",
        "num_cols = 2  # Number of columns in the grid\n",
        "num_rows = 2  # Number of rows in the grid\n"
      ],
      "metadata": {
        "id": "G5eFT7UyL0CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt for each image\n",
        "prompt = [\"a photograph of an astronaut riding a horse\"] * num_cols\n"
      ],
      "metadata": {
        "id": "ET4EYwTiL17p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = []\n",
        "for _ in range(num_rows):\n",
        "    # Generate images with custom steps and seed\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        num_inference_steps=num_inference_steps,  # Adjust the number of steps\n",
        "        generator=generator  # Use the seed generator\n",
        "    ).images\n",
        "    all_images.extend(images)"
      ],
      "metadata": {
        "id": "4ses5w3gL6Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and display the grid of images\n",
        "grid = image_grid(all_images, rows=num_rows, cols=num_cols)\n",
        "\n",
        "# Display the image grid using matplotlib\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(grid)\n",
        "plt.axis(\"off\")  # Hide axes for clean image\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t7iEmM49L81B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
