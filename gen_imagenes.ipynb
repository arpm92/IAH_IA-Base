{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arpm92/IAH_IA-Base/blob/main/gen-imagenes.ipynb)\n"
      ],
      "metadata": {
        "id": "niibNPnHG0Sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Difusi칩n Estable** 游꿛\n",
        "*...using `游빋diffusers`*\n",
        "\n",
        "Stable Diffusion es un modelo de difusi칩n latente texto-imagen creado por los investigadores e ingenieros de [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/) y [LAION](https://laion.ai/). Est치 entrenado con im치genes de 512x512 de un subconjunto de la base de datos [LAION-5B](https://laion.ai/blog/laion-5b/). Este modelo utiliza un codificador de texto congelado CLIP ViT-L/14 para condicionar el modelo a las indicaciones de texto. Con sus 860M de UNet y 123M de codificador de texto, el modelo es relativamente ligero y puede ejecutarse en muchas GPU de consumo.\n",
        "Consulta la [ficha del modelo](https://huggingface.co/CompVis/stable-diffusion) para obtener m치s informaci칩n.\n",
        "\n",
        "Este cuaderno de Colab muestra c칩mo usar Stable Diffusion con la 游뱅 Hugging Face [游빋 Diffusers library](https://github.com/huggingface/diffusers).\n",
        "\n",
        "춰Vamos a empezar!"
      ],
      "metadata": {
        "id": "KaCNC7k1HB0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. C칩mo utilizar `StableDiffusionPipeline\n",
        "\n",
        "Antes de sumergirnos en los aspectos te칩ricos de c칩mo funciona Stable Diffusion,\n",
        "vamos a probarlo un poco 游뱅.\n",
        "\n",
        "En esta secci칩n, mostramos c칩mo puede ejecutar la inferencia de texto a imagen 춰en s칩lo unas pocas l칤neas de c칩digo!"
      ],
      "metadata": {
        "id": "OI4D7ZPNHOOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuraci칩n\n",
        "\n",
        "En primer lugar, por favor, aseg칰rese de que est치 utilizando un runtime GPU para ejecutar este cuaderno, por lo que la inferencia es mucho m치s r치pida. Si el siguiente comando falla, utilice el men칰 `Runtime` de arriba y seleccione `Change runtime type`."
      ],
      "metadata": {
        "id": "ncUze4r2HSnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "ZU-tm8ZtHUdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci칩n, debes instalar `diffusers` as칤 como `scipy`, `ftfy` y `transformers`. Se utiliza `accelerate` para conseguir una carga mucho m치s r치pida."
      ],
      "metadata": {
        "id": "wU_Xo83gHhn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.11.1\n",
        "!pip install transformers scipy ftfy accelerate"
      ],
      "metadata": {
        "id": "RJshHie1HidN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuber칤a de difusi칩n estable\n",
        "\n",
        "`StableDiffusionPipeline` es un proceso de inferencia de extremo a extremo que puede utilizar para generar im치genes a partir de texto con s칩lo unas pocas l칤neas de c칩digo.\n",
        "\n",
        "Primero, cargamos los pesos pre-entrenados de todos los componentes del modelo. En este cuaderno utilizamos la versi칩n 1.4 de Stable Diffusion ([CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4)), pero hay otras variantes que puede probar:\n",
        "* [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)\n",
        "* [stabilityai/stable-diffusion-2-1-base](https://huggingface.co/stabilityai/stable-diffusion-2-1-base)\n",
        "* [stabilityai/stable-diffusion-2-1](https://huggingface.co/stabilityai/stable-diffusion-2-1). Esta versi칩n puede producir im치genes con una resoluci칩n de 768x768, mientras que las dem치s funcionan a 512x512.\n",
        "\n",
        "Adem치s del id del modelo [CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4), tambi칠n pasamos una `revision` y un `torch_dtype` espec칤ficos al m칠todo `from_pretrained`.\n",
        "\n",
        "Queremos asegurarnos de que cada Google Colab libre puede ejecutar Stable Diffusion, por lo que estamos cargando los pesos desde la rama de media precisi칩n [`fp16`](https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/fp16) y tambi칠n le decimos a `diffusers` que espere los pesos en precisi칩n float16 pasando `torch_dtype=torch.float16`.\n",
        "\n",
        "Si desea asegurar la mayor precisi칩n posible, por favor aseg칰rese de eliminar `torch_dtype=torch.float16` a costa de un mayor uso de memoria."
      ],
      "metadata": {
        "id": "iFwoKQsLHpMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)"
      ],
      "metadata": {
        "id": "9bhKT4JEHrcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "ooyN-9liHsBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y ya estamos listos para generar im치genes:"
      ],
      "metadata": {
        "id": "IE4QESAaHtJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a photograph of an astronaut riding a horse\"\n",
        "image = pipe(prompt).images[0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "\n",
        "# Now to display an image you can either save it such as:\n",
        "image.save(f\"astronaut_rides_horse.png\")\n",
        "\n",
        "# or if you're in a google colab you can directly display it with\n",
        "image"
      ],
      "metadata": {
        "id": "U4bqDC1PHwda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "generator = torch.Generator(\"cuda\").manual_seed(1024)\n",
        "\n",
        "image = pipe(prompt, generator=generator).images[0]\n",
        "\n",
        "image"
      ],
      "metadata": {
        "id": "yIfjCk9BH02S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puede cambiar el n칰mero de pasos de inferencia utilizando el argumento `num_pasos_de_inferencia`. En general, los resultados son mejores cuantos m치s pasos se utilicen. Stable Diffusion, siendo uno de los modelos m치s recientes, funciona muy bien con un n칰mero relativamente peque침o de pasos, por lo que recomendamos utilizar el valor por defecto de `50`. Si desea resultados m치s r치pidos puede utilizar un n칰mero menor.\n",
        "\n",
        "La siguiente celda utiliza la misma semilla que antes, pero con menos pasos. Observe c칩mo algunos detalles, como la cabeza del caballo o el casco, son menos realistas y est치n menos definidos que en la imagen anterior:"
      ],
      "metadata": {
        "id": "8RmdFcuRH5Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "generator = torch.Generator(\"cuda\").manual_seed(1024)\n",
        "\n",
        "image = pipe(prompt, num_inference_steps=15, generator=generator).images[0]\n",
        "\n",
        "image"
      ],
      "metadata": {
        "id": "6m7Elh9LH7d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para generar m칰ltiples im치genes para el mismo prompt, simplemente usamos una lista con el mismo prompt repetido varias veces. Enviaremos la lista a la tuber칤a en lugar de la cadena que usamos antes."
      ],
      "metadata": {
        "id": "cTxFzCbsIE4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid"
      ],
      "metadata": {
        "id": "Y8RnYmmLIGrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = 3\n",
        "prompt = [\"a photograph of an astronaut riding a horse\"] * num_images\n",
        "\n",
        "images = pipe(prompt).images\n",
        "\n",
        "grid = image_grid(images, rows=1, cols=3)\n",
        "grid"
      ],
      "metadata": {
        "id": "s88YGsOPIIcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci칩n se explica c칩mo generar una cuadr칤cula de n 칑 m im치genes."
      ],
      "metadata": {
        "id": "vfZ-Rc76IR_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = 3\n",
        "num_rows = 4\n",
        "\n",
        "prompt = [\"a photograph of an astronaut riding a horse\"] * num_cols\n",
        "\n",
        "all_images = []\n",
        "for i in range(num_rows):\n",
        "  images = pipe(prompt).images\n",
        "  all_images.extend(images)\n",
        "\n",
        "grid = image_grid(all_images, rows=num_rows, cols=num_cols)\n",
        "grid"
      ],
      "metadata": {
        "id": "NPycUI2TIOaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}