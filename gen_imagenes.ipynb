{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arpm92/IAH_IA-Base/blob/main/gen_imagenes.ipynb)\n"
      ],
      "metadata": {
        "id": "niibNPnHG0Sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stable Diffusion** 🎨\n",
        "*...using `🧨diffusers`*\n",
        "\n",
        "Stable Diffusion es un modelo de difusión latente texto-imagen creado por los investigadores e ingenieros de [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/) y [LAION](https://laion.ai/). Está entrenado con imágenes de 512x512 de un subconjunto de la base de datos [LAION-5B](https://laion.ai/blog/laion-5b/). Este modelo utiliza un codificador de texto congelado CLIP ViT-L/14 para condicionar el modelo a las indicaciones de texto. Con sus 860M de UNet y 123M de codificador de texto, el modelo es relativamente ligero y puede ejecutarse en muchas GPU de consumo.\n",
        "Consulta la [ficha del modelo](https://huggingface.co/CompVis/stable-diffusion) para obtener más información.\n",
        "\n",
        "Este cuaderno de Colab muestra cómo usar Stable Diffusion con la 🤗 Hugging Face [🧨 Diffusers library](https://github.com/huggingface/diffusers).\n",
        "\n",
        "¡Vamos a empezar!"
      ],
      "metadata": {
        "id": "KaCNC7k1HB0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Cómo utilizar `StableDiffusionPipeline\n",
        "\n",
        "Antes de sumergirnos en los aspectos teóricos de cómo funciona Stable Diffusion,\n",
        "vamos a probarlo un poco 🤗.\n",
        "\n",
        "En esta sección, mostramos cómo puede ejecutar la inferencia de texto a imagen ¡en sólo unas pocas líneas de código!"
      ],
      "metadata": {
        "id": "OI4D7ZPNHOOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuración\n",
        "\n",
        "En primer lugar, por favor, asegúrese de que está utilizando un runtime GPU para ejecutar este cuaderno, por lo que la inferencia es mucho más rápida. Si el siguiente comando falla, utilice el menú `Runtime` de arriba y seleccione `Change runtime type`."
      ],
      "metadata": {
        "id": "ncUze4r2HSnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "ZU-tm8ZtHUdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages: diffusers, transformers, and accelerate\n",
        "!pip install diffusers transformers accelerate torch --quiet\n",
        "\n",
        "# Install a specific version of the xformers package for performance improvements\n",
        "!pip install xformers --quiet"
      ],
      "metadata": {
        "id": "rC4jbHzJLmuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "FGGx-gNDLsTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Stable Diffusion model from the Hugging Face Model Hub\n",
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "\n",
        "# Move the pipeline to GPU for faster generation\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "fuAtQBZTLusC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a grid of images\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows * cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols * w, rows * h))\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "\n",
        "    return grid"
      ],
      "metadata": {
        "id": "8JdEwVvcLw1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of inference steps\n",
        "num_inference_steps = 50\n",
        "# Set the seed for reproducibility\n",
        "generator = torch.manual_seed(42)  # Change seed for different results"
      ],
      "metadata": {
        "id": "qcp9vKQ1Njhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define grid size\n",
        "num_cols = 2  # Number of columns in the grid\n",
        "num_rows = 2  # Number of rows in the grid\n"
      ],
      "metadata": {
        "id": "G5eFT7UyL0CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt for each image\n",
        "prompt = [\"a photograph of an astronaut riding a horse\"] * num_cols\n"
      ],
      "metadata": {
        "id": "ET4EYwTiL17p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = []\n",
        "for _ in range(num_rows):\n",
        "    # Generate images with custom steps and seed\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        num_inference_steps=num_inference_steps,  # Adjust the number of steps\n",
        "        generator=generator  # Use the seed generator\n",
        "    ).images\n",
        "    all_images.extend(images)"
      ],
      "metadata": {
        "id": "4ses5w3gL6Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and display the grid of images\n",
        "grid = image_grid(all_images, rows=num_rows, cols=num_cols)\n",
        "\n",
        "# Display the image grid using matplotlib\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(grid)\n",
        "plt.axis(\"off\")  # Hide axes for clean image\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t7iEmM49L81B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
